{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "The data source is a REDCap audit logging file, which can be exported by going to REDCap > Sidebar > Logging > Export all logging (CSV). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_colwidth = 75\n",
    "\n",
    "# import logging file from REDCap (REDCap > Sidebar > Logging > Export all logging (CSV))\n",
    "log = pd.read_csv('data/raw/PCORIACPRecruitment_Logging_2020-12-26_0615.csv',encoding = \"ISO-8859-1\")\n",
    "\n",
    "# import patient demographics from Clarity/other repository\n",
    "Patient_Demographics = pd.read_csv('data/raw/demographics.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_missingness(dataframe,dataframe_name):\n",
    "    print(\"Length of %s table: %d\" % (dataframe_name,len(dataframe)))\n",
    "    print()\n",
    "    print( \"Count Missing in Each Column:\")\n",
    "    print(dataframe.isnull().sum())\n",
    "\n",
    "def print_counts_per_column(dataframe,column_list):\n",
    "    for col_name in column_list:\n",
    "        print('Column Name: %s' % col_name)\n",
    "        print(dataframe[col_name].value_counts())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "### Split logging file into round 1 / 2 / 3 call dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Round 1 Call Updates:  2773\n",
      "# of Round 2 Call Updates:  370\n",
      "# of Round 3 Call Updates:  29\n",
      "\n",
      "Total Call Updates:  3172\n",
      "# of Round 1 Caregiver Call Updates:  4\n",
      "# of Round 2 Caregiver Call Updates:  0\n",
      "# of Round 3 Caregiver Call Updates:  0\n"
     ]
    }
   ],
   "source": [
    "# make a new df with only REDCap Patient Record Updates\n",
    "log_updates = log[log['Action'].str.contains(\"Updated\")].copy()\n",
    "\n",
    "# make a new df with only REDCap Patient Record Updates + Phone Call 1 / 2 / 3 Attempts\n",
    "# assumes that RA updating the contact date field in Internal REDCAp = call completed\n",
    "log_updates_call1 = log_updates[log_updates['List of Data Changes OR Fields Exported'].str.contains(\"contact1_dt\", na=False)].copy()\n",
    "log_updates_call2 = log_updates[log_updates['List of Data Changes OR Fields Exported'].str.contains(\"contact2_dt\", na=False)].copy()\n",
    "log_updates_call3 = log_updates[log_updates['List of Data Changes OR Fields Exported'].str.contains(\"contact3_dt\", na=False)].copy()\n",
    "\n",
    "log_updates_caregiver_call1 = log_updates[log_updates['List of Data Changes OR Fields Exported'].str.contains(\"caregiver_contact1_dt_vad\", na=False)].copy()\n",
    "log_updates_caregiver_call2 = log_updates[log_updates['List of Data Changes OR Fields Exported'].str.contains(\"caregiver_contact2_dt_vad\", na=False)].copy()\n",
    "log_updates_caregiver_call3 = log_updates[log_updates['List of Data Changes OR Fields Exported'].str.contains(\"caregiver_contact3_dt_vad\", na=False)].copy()\n",
    "\n",
    "print(\"# of Round 1 Call Updates: \", log_updates_call1.shape[0])\n",
    "print(\"# of Round 2 Call Updates: \", log_updates_call2.shape[0])\n",
    "print(\"# of Round 3 Call Updates: \", log_updates_call3.shape[0])\n",
    "print(\"\\nTotal Call Updates: \", log_updates_call1.shape[0] + log_updates_call2.shape[0] + log_updates_call3.shape[0])\n",
    "print(\"# of Round 1 Caregiver Call Updates: \", log_updates_caregiver_call1.shape[0])\n",
    "print(\"# of Round 2 Caregiver Call Updates: \", log_updates_caregiver_call2.shape[0])\n",
    "print(\"# of Round 3 Caregiver Call Updates: \", log_updates_caregiver_call3.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain study ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract study ID from long string ('Action')\n",
    "log_updates_call1['study_id'] = log_updates_call1['Action'].str.split(' ').str[2]\n",
    "log_updates_call2['study_id'] = log_updates_call2['Action'].str.split(' ').str[2]\n",
    "log_updates_call3['study_id'] = log_updates_call3['Action'].str.split(' ').str[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original round 1 duplicates:  40\n",
      "original round 2 duplicates:  2\n",
      "original round 3 duplicates:  0\n",
      "\n",
      "new round 1 duplicates:  0\n",
      "new round 2 duplicates:  0\n",
      "new round 3 duplicates:  0\n",
      "\n",
      "# of Round 1 Calls:  2752\n",
      "# of Round 2 Calls:  369\n",
      "# of Round 3 Calls:  29\n",
      "\n",
      "Total Calls:  3150\n"
     ]
    }
   ],
   "source": [
    "# convert dtype from string to datetime\n",
    "log_updates_call1['Time / Date'] = pd.to_datetime(log_updates_call1['Time / Date'])\n",
    "log_updates_call2['Time / Date'] = pd.to_datetime(log_updates_call2['Time / Date'])\n",
    "log_updates_call3['Time / Date'] = pd.to_datetime(log_updates_call3['Time / Date'])\n",
    "\n",
    "# sort calls by date from oldest to newest\n",
    "log_updates_call1 = log_updates_call1.sort_values(by=['Time / Date'])\n",
    "log_updates_call2 = log_updates_call2.sort_values(by=['Time / Date'])\n",
    "log_updates_call3 = log_updates_call3.sort_values(by=['Time / Date'])\n",
    "\n",
    "# check for duplicate updates to 1 study ID\n",
    "print(\"original round 1 duplicates: \", log_updates_call1[log_updates_call1['study_id'].duplicated(keep=False)].shape[0])\n",
    "print(\"original round 2 duplicates: \", log_updates_call2[log_updates_call2['study_id'].duplicated(keep=False)].shape[0])\n",
    "print(\"original round 3 duplicates: \", log_updates_call3[log_updates_call3['study_id'].duplicated(keep=False)].shape[0])\n",
    "\n",
    "# when there are multiple updates to 1 study ID, only take the most recent update\n",
    "unique_log_updates_call1 = log_updates_call1.drop_duplicates(subset=['study_id'], keep='last')\n",
    "unique_log_updates_call2 = log_updates_call2.drop_duplicates(subset=['study_id'], keep='last')\n",
    "unique_log_updates_call3 = log_updates_call3.drop_duplicates(subset=['study_id'], keep='last')\n",
    "\n",
    "# check for duplicate updates to 1 study ID\n",
    "print(\"\\nnew round 1 duplicates: \", unique_log_updates_call1[unique_log_updates_call1['study_id'].duplicated(keep=False)].shape[0])\n",
    "print(\"new round 2 duplicates: \", unique_log_updates_call2[unique_log_updates_call2['study_id'].duplicated(keep=False)].shape[0])\n",
    "print(\"new round 3 duplicates: \", unique_log_updates_call3[unique_log_updates_call3['study_id'].duplicated(keep=False)].shape[0])\n",
    "\n",
    "print(\"\\n# of Round 1 Calls: \", unique_log_updates_call1.shape[0])\n",
    "print(\"# of Round 2 Calls: \", unique_log_updates_call2.shape[0])\n",
    "print(\"# of Round 3 Calls: \", unique_log_updates_call3.shape[0])\n",
    "print(\"\\nTotal Calls: \", unique_log_updates_call1.shape[0] + unique_log_updates_call2.shape[0] + unique_log_updates_call3.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract useful data from strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract individual updates from long string ('List of Data Changes OR Fields Exported'), based on delimiter ','\n",
    "split_unique_log_updates_call1 = pd.concat([unique_log_updates_call1['study_id'], \n",
    "                                     unique_log_updates_call1['List of Data Changes OR Fields Exported'].str.split(',', expand=True)],\n",
    "                                    axis=1,)\n",
    "split_unique_log_updates_call2 = pd.concat([unique_log_updates_call2['study_id'],\n",
    "                                     unique_log_updates_call2['List of Data Changes OR Fields Exported'].str.split(',', expand=True)],\n",
    "                                    axis=1,)\n",
    "split_unique_log_updates_call3 = pd.concat([unique_log_updates_call3['study_id'],\n",
    "                                     unique_log_updates_call3['List of Data Changes OR Fields Exported'].str.split(',', expand=True)],\n",
    "                                    axis=1,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extract updates specific to round 1 / 2 / 3 phone calls \n",
    "# make a boolean mask of all columns in the round 1 / 2 / 3 dataframe, True for matching strings\n",
    "# forward fill rows with matching strings and take only the last value \n",
    "# basically picks out the matching value regardless of column location and places it into the correct column\n",
    "\n",
    "# round 1\n",
    "df = split_unique_log_updates_call1.copy()\n",
    "strings = ['contact1_dt', 'contact1_output', 'contact1_nt', 'verbal_yn']\n",
    "updates_round_1 = pd.DataFrame()\n",
    "\n",
    "for s in strings:\n",
    "    for col in df: \n",
    "        df[col] = df[col].mask(~df[col].str.contains(s, na=False))\n",
    "    updates_round_1[s] = df.ffill(axis=1).iloc[:, -1]\n",
    "    df = split_unique_log_updates_call1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extracts date from 'contact1_dt' output\n",
    "updates_round_1.iloc[:,0] = pd.to_datetime(updates_round_1.iloc[:,0].str.extract('(\\d{1,4}-\\d{1,2}-\\d{1,2})')[0])\n",
    "\n",
    "# convert call code outputs to real words, per UCI's REDCap Codebook \n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '1'\": \"No answer/unable to leave VM/busy/disconnected\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '2'\": \"Left a message\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '3'\": \"Call back later\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '4'\": \"Hasn't received packet yet, call back in one week\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '5'\": \"Hasn't received packet and team needs to resend in the mail\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '6'\": \"Send link to the survey\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '7'\": \"Completed survey by phone\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '8'\": \"Patient refused\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '9'\": \"Deceased\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '10'\": \"Other Notes\"}, regex=True)\n",
    "\n",
    "updates_round_1.iloc[:,3] = updates_round_1.iloc[:,3].replace({\"verbal_yn = '0'\": \"No Verbal Consent\"}, regex=True)\n",
    "updates_round_1.iloc[:,3] = updates_round_1.iloc[:,3].replace({\"verbal_yn = '1'\": \"Yes Verbal Consent\"}, regex=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# round 2\n",
    "df = split_unique_log_updates_call2.copy()\n",
    "strings = ['contact2_dt', 'contact2_output', 'contact2_nt', 'verbal_yn']\n",
    "updates_round_2 = pd.DataFrame()\n",
    "\n",
    "for s in strings:\n",
    "    for col in df: \n",
    "        df[col] = df[col].mask(~df[col].str.contains(s, na=False))\n",
    "    updates_round_2[s] = df.ffill(axis=1).iloc[:, -1]\n",
    "    df = split_unique_log_updates_call2.copy()\n",
    "\n",
    "updates_round_2.iloc[:,0] = pd.to_datetime(updates_round_2.iloc[:,0].str.extract('(\\d{1,4}-\\d{1,2}-\\d{1,2})')[0])\n",
    "\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '1'\": \"No answer/unable to leave VM/busy/disconnected\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '2'\": \"Left a message\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '3'\": \"Call back later\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '4'\": \"Hasn't received packet yet, call back in one week\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '5'\": \"Hasn't received packet and team needs to resend in the mail\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '6'\": \"Send link to the survey\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '7'\": \"Completed survey by phone\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '8'\": \"Patient refused\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '9'\": \"Deceased\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '10'\": \"Other Notes\"}, regex=True)\n",
    "\n",
    "updates_round_2.iloc[:,3] = updates_round_2.iloc[:,3].replace({\"verbal_yn = '0'\": \"No Verbal Consent\"}, regex=True)\n",
    "updates_round_2.iloc[:,3] = updates_round_2.iloc[:,3].replace({\"verbal_yn = '1'\": \"Yes Verbal Consent\"}, regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# round 3\n",
    "df = split_unique_log_updates_call3.copy()\n",
    "strings = ['contact3_dt', 'contact3_output', 'contact3_nt', 'verbal_yn']\n",
    "updates_round_3 = pd.DataFrame()\n",
    "\n",
    "for s in strings:\n",
    "    for col in df: \n",
    "        df[col] = df[col].mask(~df[col].str.contains(s, na=False))\n",
    "    updates_round_3[s] = df.ffill(axis=1).iloc[:, -1]\n",
    "    df = split_unique_log_updates_call3.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "updates_round_3.iloc[:,0] = pd.to_datetime(updates_round_3.iloc[:,0].str.extract('(\\d{1,4}-\\d{1,2}-\\d{1,2})')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '1'\": \"No answer/unable to leave VM/busy/disconnected\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '2'\": \"Left a message\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '3'\": \"Call back later\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '4'\": \"Hasn't received packet yet, call back in one week\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '5'\": \"Hasn't received packet and team needs to resend in the mail\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '6'\": \"Send link to the survey\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '7'\": \"Completed survey by phone\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '8'\": \"Patient refused\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '9'\": \"Deceased\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '10'\": \"Other Notes\"}, regex=True)\n",
    "# neded to force str datatype on verbal_yn because all the entries were NaN\n",
    "updates_round_3.iloc[:,3] = updates_round_3.iloc[:,3].astype(str) \n",
    "updates_round_3.iloc[:,3] = updates_round_3.iloc[:,3].replace({\"verbal_yn = '0'\": \"No Verbal Consent\"}, regex=True)\n",
    "updates_round_3.iloc[:,3] = updates_round_3.iloc[:,3].replace({\"verbal_yn = '1'\": \"Yes Verbal Consent\"}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names:  ['study_id', 'username_1', 'timestamp_1', 'call_date_1', 'call_output_1', 'call_notes_1', 'verbal_consent_1']\n",
      "shape of round 1 dataset:  (2752, 7)\n",
      "shape of round 2 dataset:  (369, 7)\n",
      "shape of round 3 dataset:  (29, 7)\n"
     ]
    }
   ],
   "source": [
    "# create new dataframes with relevant columns for round 1 / 2 / 3 calls \n",
    "\n",
    "# round 1\n",
    "clean_round_1 = split_unique_log_updates_call1['study_id'].copy()\n",
    "clean_round_1 = pd.concat((clean_round_1, unique_log_updates_call1['Username']), axis=1)\n",
    "clean_round_1 = pd.concat((clean_round_1, unique_log_updates_call1['Time / Date']), axis=1)\n",
    "clean_round_1 = pd.concat((clean_round_1, updates_round_1), axis=1)\n",
    "clean_round_1.columns = ['study_id', 'username_1', 'timestamp_1', 'call_date_1', 'call_output_1', 'call_notes_1', 'verbal_consent_1']\n",
    "\n",
    "\n",
    "# round 2 \n",
    "clean_round_2 = split_unique_log_updates_call2['study_id'].copy()\n",
    "clean_round_2 = pd.concat((clean_round_2, unique_log_updates_call2['Username']), axis=1)\n",
    "clean_round_2 = pd.concat((clean_round_2, unique_log_updates_call2['Time / Date']), axis=1)\n",
    "clean_round_2 = pd.concat((clean_round_2, updates_round_2), axis=1)\n",
    "clean_round_2.columns = ['study_id', 'username_2', 'timestamp_2', 'call_date_2', 'call_output_2', 'call_notes_2', 'verbal_consent_2']\n",
    "\n",
    "\n",
    "# round 3\n",
    "clean_round_3 = split_unique_log_updates_call3['study_id'].copy()\n",
    "clean_round_3 = pd.concat((clean_round_3, unique_log_updates_call3['Username']), axis=1)\n",
    "clean_round_3 = pd.concat((clean_round_3, unique_log_updates_call3['Time / Date']), axis=1)\n",
    "clean_round_3 = pd.concat((clean_round_3, updates_round_3), axis=1)\n",
    "clean_round_3.columns = ['study_id', 'username_3', 'timestamp_3', 'call_date_3', 'call_output_3', 'call_notes_3', 'verbal_consent_3']\n",
    "\n",
    "\n",
    "print(\"column names: \", clean_round_1.columns.values.tolist())\n",
    "print(\"shape of round 1 dataset: \", clean_round_1.shape)\n",
    "print(\"shape of round 2 dataset: \", clean_round_2.shape)\n",
    "print(\"shape of round 3 dataset: \", clean_round_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge round 1 / 2 / 3 dataframes on study ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge round 1 / 2 / 3 calls so there is 1 patient per line with all call data in columns \n",
    "clean_1_2_calls = pd.merge(clean_round_1, clean_round_2, how=\"left\", on='study_id')\n",
    "clean_all_calls = pd.merge(clean_1_2_calls, clean_round_3, how=\"left\", on='study_id')\n",
    "\n",
    "#print(\"Example output for each patient:\\n\\n\", clean_all_calls.iloc[200,:])\n",
    "\n",
    "\n",
    "# TODO: merge Clarity extract to obtain other useful data (age, sex, race, ethnicity, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>username_1</th>\n",
       "      <th>timestamp_1</th>\n",
       "      <th>call_date_1</th>\n",
       "      <th>call_output_1</th>\n",
       "      <th>call_notes_1</th>\n",
       "      <th>verbal_consent_1</th>\n",
       "      <th>username_2</th>\n",
       "      <th>timestamp_2</th>\n",
       "      <th>call_date_2</th>\n",
       "      <th>call_output_2</th>\n",
       "      <th>call_notes_2</th>\n",
       "      <th>verbal_consent_2</th>\n",
       "      <th>username_3</th>\n",
       "      <th>timestamp_3</th>\n",
       "      <th>call_date_3</th>\n",
       "      <th>call_output_3</th>\n",
       "      <th>call_notes_3</th>\n",
       "      <th>verbal_consent_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000003</td>\n",
       "      <td>jsanz</td>\n",
       "      <td>2019-07-12 06:58:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1000029534</td>\n",
       "      <td>jantoniolopez</td>\n",
       "      <td>2019-09-05 13:13:00</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>Completed survey by phone</td>\n",
       "      <td>contact1_nt = 'Patient signed consent and HIPAA forms and will mail ba...</td>\n",
       "      <td>Yes Verbal Consent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1000030950</td>\n",
       "      <td>kmsantos</td>\n",
       "      <td>2019-10-08 08:10:00</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>Completed survey by phone</td>\n",
       "      <td>contact1_nt = 'Pt called in to complete survey and scored 19/20 on dep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1000030428</td>\n",
       "      <td>adepaolisdickey</td>\n",
       "      <td>2019-10-23 13:46:00</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>Other Notes</td>\n",
       "      <td>contact1_nt = 'States he sent in survey already'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1000029439</td>\n",
       "      <td>adepaolisdickey</td>\n",
       "      <td>2019-10-23 13:50:00</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>Call back later</td>\n",
       "      <td>contact1_nt = 'States just returned from dialysis and is not feeling w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     study_id       username_1         timestamp_1 call_date_1  \\\n",
       "0     1000003            jsanz 2019-07-12 06:58:00         NaT   \n",
       "1  1000029534    jantoniolopez 2019-09-05 13:13:00  2019-09-05   \n",
       "2  1000030950         kmsantos 2019-10-08 08:10:00  2019-10-07   \n",
       "3  1000030428  adepaolisdickey 2019-10-23 13:46:00  2019-10-23   \n",
       "4  1000029439  adepaolisdickey 2019-10-23 13:50:00  2019-10-23   \n",
       "\n",
       "                call_output_1  \\\n",
       "0                         NaN   \n",
       "1   Completed survey by phone   \n",
       "2   Completed survey by phone   \n",
       "3                 Other Notes   \n",
       "4             Call back later   \n",
       "\n",
       "                                                                 call_notes_1  \\\n",
       "0                                                                         NaN   \n",
       "1   contact1_nt = 'Patient signed consent and HIPAA forms and will mail ba...   \n",
       "2   contact1_nt = 'Pt called in to complete survey and scored 19/20 on dep...   \n",
       "3                            contact1_nt = 'States he sent in survey already'   \n",
       "4   contact1_nt = 'States just returned from dialysis and is not feeling w...   \n",
       "\n",
       "      verbal_consent_1 username_2 timestamp_2 call_date_2 call_output_2  \\\n",
       "0                  NaN        NaN         NaT         NaT           NaN   \n",
       "1   Yes Verbal Consent        NaN         NaT         NaT           NaN   \n",
       "2                  NaN        NaN         NaT         NaT           NaN   \n",
       "3                  NaN        NaN         NaT         NaT           NaN   \n",
       "4                  NaN        NaN         NaT         NaT           NaN   \n",
       "\n",
       "  call_notes_2 verbal_consent_2 username_3 timestamp_3 call_date_3  \\\n",
       "0          NaN              NaN        NaN         NaT         NaT   \n",
       "1          NaN              NaN        NaN         NaT         NaT   \n",
       "2          NaN              NaN        NaN         NaT         NaT   \n",
       "3          NaN              NaN        NaN         NaT         NaT   \n",
       "4          NaN              NaN        NaN         NaT         NaT   \n",
       "\n",
       "  call_output_3 call_notes_3 verbal_consent_3  \n",
       "0           NaN          NaN              NaN  \n",
       "1           NaN          NaN              NaN  \n",
       "2           NaN          NaN              NaN  \n",
       "3           NaN          NaN              NaN  \n",
       "4           NaN          NaN              NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_all_calls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient_Demographics:  5,116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "study_id                       object\n",
       "gender                         object\n",
       "race                           object\n",
       "ethnicity                      object\n",
       "marital_status                 object\n",
       "religion                       object\n",
       "calc_current_age_death_age    float64\n",
       "svi_socio_econ                float64\n",
       "svi_hcomp_lang                float64\n",
       "svi_mino_lang                 float64\n",
       "svi_htyp_trans                float64\n",
       "svi_total                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standarize demographics headers\n",
    "Patient_Demographics.columns = Patient_Demographics.columns.str.lower()# get counts\n",
    "print('Patient_Demographics: ', format(Patient_Demographics.shape[0],  ',d'))\n",
    "\n",
    "# convert study_id to object to match clean_all_calls.study_id\n",
    "# clean_all_calls.dtypes\n",
    "Patient_Demographics['study_id'] = Patient_Demographics['study_id'].astype(object)\n",
    "Patient_Demographics.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Patient_Demographics table: 5116\n",
      "\n",
      "Count Missing in Each Column:\n",
      "study_id                         0\n",
      "gender                           5\n",
      "race                             6\n",
      "ethnicity                        5\n",
      "marital_status                   5\n",
      "religion                         5\n",
      "calc_current_age_death_age       0\n",
      "svi_socio_econ                2594\n",
      "svi_hcomp_lang                2594\n",
      "svi_mino_lang                 2594\n",
      "svi_htyp_trans                2594\n",
      "svi_total                     2594\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    " general_missingness(Patient_Demographics,'Patient_Demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>religion</th>\n",
       "      <th>calc_current_age_death_age</th>\n",
       "      <th>svi_socio_econ</th>\n",
       "      <th>svi_hcomp_lang</th>\n",
       "      <th>svi_mino_lang</th>\n",
       "      <th>svi_htyp_trans</th>\n",
       "      <th>svi_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000026253</td>\n",
       "      <td>Male</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000026254</td>\n",
       "      <td>Male</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>Presbyterian</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.6434</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.0964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000026255</td>\n",
       "      <td>Female</td>\n",
       "      <td>Other</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Single</td>\n",
       "      <td>Patient Refused</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000026257</td>\n",
       "      <td>Female</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>0.2873</td>\n",
       "      <td>0.0947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000026258</td>\n",
       "      <td>Male</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>None</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender                race               ethnicity marital_status  \\\n",
       "study_id                                                                        \n",
       "1000026253    Male  White or Caucasian  Not Hispanic or Latino        Widowed   \n",
       "1000026254    Male  White or Caucasian  Not Hispanic or Latino        Married   \n",
       "1000026255  Female               Other  Not Hispanic or Latino         Single   \n",
       "1000026257  Female  White or Caucasian  Not Hispanic or Latino        Widowed   \n",
       "1000026258    Male  White or Caucasian  Not Hispanic or Latino        Married   \n",
       "\n",
       "                   religion  calc_current_age_death_age  svi_socio_econ  \\\n",
       "study_id                                                                  \n",
       "1000026253           Jewish                        87.0             NaN   \n",
       "1000026254     Presbyterian                        62.0          0.0271   \n",
       "1000026255  Patient Refused                       999.0             NaN   \n",
       "1000026257         Catholic                       999.0          0.0347   \n",
       "1000026258             None                        83.0             NaN   \n",
       "\n",
       "            svi_hcomp_lang  svi_mino_lang  svi_htyp_trans  svi_total  \n",
       "study_id                                                              \n",
       "1000026253             NaN            NaN             NaN        NaN  \n",
       "1000026254          0.6434         0.0444          0.1711     0.0964  \n",
       "1000026255             NaN            NaN             NaN        NaN  \n",
       "1000026257          0.1145         0.2684          0.2873     0.0947  \n",
       "1000026258             NaN            NaN             NaN        NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at demographics table\n",
    "Patient_Demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name: study_id\n",
      "1000032255    1\n",
      "1000026663    1\n",
      "1000028702    1\n",
      "1000026655    1\n",
      "1000030753    1\n",
      "             ..\n",
      "1000031514    1\n",
      "1000029469    1\n",
      "1000031518    1\n",
      "1000027424    1\n",
      "1000030208    1\n",
      "Name: study_id, Length: 5116, dtype: int64\n",
      "\n",
      "Column Name: gender\n",
      "Male      2608\n",
      "Female    2503\n",
      "Name: gender, dtype: int64\n",
      "\n",
      "Column Name: race\n",
      "White or Caucasian                           3248\n",
      "Other                                         682\n",
      "Asian                                         492\n",
      "Black or African American                     480\n",
      "Patient Refused                               102\n",
      "Multiple Races                                 58\n",
      "Unknown                                        30\n",
      "American Indian or Alaska Native               13\n",
      "Native Hawaiian or Other Pacific Islander       5\n",
      "Name: race, dtype: int64\n",
      "\n",
      "Column Name: ethnicity\n",
      "Not Hispanic or Latino                  4205\n",
      "Hispanic or Latino                       568\n",
      "Patient Refused                          139\n",
      "Mexican, Mexican American, Chicano/a     108\n",
      "Hispanic/Spanish origin Other             47\n",
      "Unknown                                   31\n",
      "Cuban                                      9\n",
      "Puerto Rican                               4\n",
      "Name: ethnicity, dtype: int64\n",
      "\n",
      "Column Name: marital_status\n",
      "Married                     2580\n",
      "Single                      1037\n",
      "Widowed                      849\n",
      "Divorced                     541\n",
      "Legally Separated             33\n",
      "Unknown                       25\n",
      "Significant Other             17\n",
      "Other                         12\n",
      "Life Partner                   8\n",
      "Reg Domestic Partner RDP       7\n",
      "Widowed RDP                    1\n",
      "Dissolved RDP                  1\n",
      "Name: marital_status, dtype: int64\n",
      "\n",
      "Column Name: religion\n",
      "Catholic                        1152\n",
      "None                             899\n",
      "Christian                        590\n",
      "Jewish                           492\n",
      "Unknown                          482\n",
      "No Religious Preference          449\n",
      "Protestant                       199\n",
      "Baptist                          124\n",
      "Other                             91\n",
      "Patient Refused                   88\n",
      "Buddhist                          81\n",
      "Muslim                            63\n",
      "Methodist                         49\n",
      "Episcopalian                      44\n",
      "Presbyterian                      44\n",
      "Lutheran - Free                   27\n",
      "Spiritual But Not Religious       23\n",
      "Latter-Day Saints                 22\n",
      "Non-Denominational Christian      22\n",
      "Hindu                             21\n",
      "Lutheran                          17\n",
      "Greek Orthodox                    15\n",
      "Christian Orthodox                15\n",
      "Pentecostal                       13\n",
      "Baha'i                             8\n",
      "Atheist                            8\n",
      "Unitarian                          7\n",
      "Jehovah's Witness                  6\n",
      "Old Catholic                       5\n",
      "Agnostic                           5\n",
      "Jewish Reform                      5\n",
      "Seventh Day Adventist              4\n",
      "Religious Scientist                3\n",
      "Sikh                               3\n",
      "Church of Christ                   2\n",
      "Christian Scientist                2\n",
      "Lutheran - Missouri Synod          2\n",
      "Apostolic                          2\n",
      "Pagan                              2\n",
      "Coptic Orthodox                    2\n",
      "Unitarian Universalist             2\n",
      "Armenian Orthodox                  2\n",
      "Evangelical                        2\n",
      "Anglican                           2\n",
      "Scientologist                      1\n",
      "Jewish Conservative                1\n",
      "Ethiopian Orthodox                 1\n",
      "Jewish Orthodox                    1\n",
      "Messianic Jew                      1\n",
      "Foursquare                         1\n",
      "Eastern Orthodox                   1\n",
      "Free Methodist                     1\n",
      "United Methodist                   1\n",
      "Unity                              1\n",
      "Lutheran - Wisconsin Synod         1\n",
      "Disciples of Christ                1\n",
      "Wiccan                             1\n",
      "Quaker                             1\n",
      "Taoist                             1\n",
      "Name: religion, dtype: int64\n",
      "\n",
      "Column Name: calc_current_age_death_age\n",
      "999.0    581\n",
      "77.0     232\n",
      "76.0     231\n",
      "78.0     213\n",
      "80.0     203\n",
      "        ... \n",
      "83.3       1\n",
      "88.5       1\n",
      "77.4       1\n",
      "79.7       1\n",
      "82.3       1\n",
      "Name: calc_current_age_death_age, Length: 126, dtype: int64\n",
      "\n",
      "Column Name: svi_socio_econ\n",
      "0.1782    21\n",
      "0.1036    20\n",
      "0.3076    20\n",
      "0.1973    16\n",
      "0.1499    16\n",
      "          ..\n",
      "0.0825     1\n",
      "0.8270     1\n",
      "0.3068     1\n",
      "0.4166     1\n",
      "0.7500     1\n",
      "Name: svi_socio_econ, Length: 991, dtype: int64\n",
      "\n",
      "Column Name: svi_hcomp_lang\n",
      "0.2755    22\n",
      "0.0886    20\n",
      "0.1772    20\n",
      "0.1387    16\n",
      "0.1527    16\n",
      "          ..\n",
      "0.4213     1\n",
      "0.2930     1\n",
      "0.6543     1\n",
      "0.8921     1\n",
      "0.7389     1\n",
      "Name: svi_hcomp_lang, Length: 980, dtype: int64\n",
      "\n",
      "Column Name: svi_mino_lang\n",
      "0.3112    21\n",
      "0.0820    20\n",
      "0.1262    20\n",
      "0.0658    16\n",
      "0.2312    16\n",
      "          ..\n",
      "0.8210     1\n",
      "0.9944     1\n",
      "0.2499     1\n",
      "0.7040     1\n",
      "1.0000     1\n",
      "Name: svi_mino_lang, Length: 967, dtype: int64\n",
      "\n",
      "Column Name: svi_htyp_trans\n",
      "0.9024    21\n",
      "0.2679    20\n",
      "0.5223    20\n",
      "0.3336    16\n",
      "0.5799    16\n",
      "          ..\n",
      "0.6490     1\n",
      "0.7218     1\n",
      "0.6821     1\n",
      "0.6162     1\n",
      "0.9283     1\n",
      "Name: svi_htyp_trans, Length: 990, dtype: int64\n",
      "\n",
      "Column Name: svi_total\n",
      "0.4235    21\n",
      "0.0835    20\n",
      "0.2544    20\n",
      "0.1179    16\n",
      "0.2584    16\n",
      "          ..\n",
      "0.9984     1\n",
      "0.1586     1\n",
      "0.3007     1\n",
      "0.4252     1\n",
      "0.7916     1\n",
      "Name: svi_total, Length: 998, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create field list\n",
    "column_list = list(Patient_Demographics)\n",
    "# Print counts per column\n",
    "print_counts_per_column(Patient_Demographics,column_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up demo df before merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add demographic and socio-economic indicators to call df\n",
    "clean_all_calls_demo = pd.merge(clean_all_calls,Patient_Demographics, how=\"left\", on='study_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>username_1</th>\n",
       "      <th>timestamp_1</th>\n",
       "      <th>call_date_1</th>\n",
       "      <th>call_output_1</th>\n",
       "      <th>call_notes_1</th>\n",
       "      <th>verbal_consent_1</th>\n",
       "      <th>username_2</th>\n",
       "      <th>timestamp_2</th>\n",
       "      <th>call_date_2</th>\n",
       "      <th>...</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>religion</th>\n",
       "      <th>calc_current_age_death_age</th>\n",
       "      <th>svi_socio_econ</th>\n",
       "      <th>svi_hcomp_lang</th>\n",
       "      <th>svi_mino_lang</th>\n",
       "      <th>svi_htyp_trans</th>\n",
       "      <th>svi_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000003</td>\n",
       "      <td>jsanz</td>\n",
       "      <td>2019-07-12 06:58:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1000029534</td>\n",
       "      <td>jantoniolopez</td>\n",
       "      <td>2019-09-05 13:13:00</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>Completed survey by phone</td>\n",
       "      <td>contact1_nt = 'Patient signed consent and HIPAA forms and will mail ba...</td>\n",
       "      <td>Yes Verbal Consent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1000030950</td>\n",
       "      <td>kmsantos</td>\n",
       "      <td>2019-10-08 08:10:00</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>Completed survey by phone</td>\n",
       "      <td>contact1_nt = 'Pt called in to complete survey and scored 19/20 on dep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1000030428</td>\n",
       "      <td>adepaolisdickey</td>\n",
       "      <td>2019-10-23 13:46:00</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>Other Notes</td>\n",
       "      <td>contact1_nt = 'States he sent in survey already'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1000029439</td>\n",
       "      <td>adepaolisdickey</td>\n",
       "      <td>2019-10-23 13:50:00</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>Call back later</td>\n",
       "      <td>contact1_nt = 'States just returned from dialysis and is not feeling w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     study_id       username_1         timestamp_1 call_date_1  \\\n",
       "0     1000003            jsanz 2019-07-12 06:58:00         NaT   \n",
       "1  1000029534    jantoniolopez 2019-09-05 13:13:00  2019-09-05   \n",
       "2  1000030950         kmsantos 2019-10-08 08:10:00  2019-10-07   \n",
       "3  1000030428  adepaolisdickey 2019-10-23 13:46:00  2019-10-23   \n",
       "4  1000029439  adepaolisdickey 2019-10-23 13:50:00  2019-10-23   \n",
       "\n",
       "                call_output_1  \\\n",
       "0                         NaN   \n",
       "1   Completed survey by phone   \n",
       "2   Completed survey by phone   \n",
       "3                 Other Notes   \n",
       "4             Call back later   \n",
       "\n",
       "                                                                 call_notes_1  \\\n",
       "0                                                                         NaN   \n",
       "1   contact1_nt = 'Patient signed consent and HIPAA forms and will mail ba...   \n",
       "2   contact1_nt = 'Pt called in to complete survey and scored 19/20 on dep...   \n",
       "3                            contact1_nt = 'States he sent in survey already'   \n",
       "4   contact1_nt = 'States just returned from dialysis and is not feeling w...   \n",
       "\n",
       "      verbal_consent_1 username_2 timestamp_2 call_date_2  ... race ethnicity  \\\n",
       "0                  NaN        NaN         NaT         NaT  ...  NaN       NaN   \n",
       "1   Yes Verbal Consent        NaN         NaT         NaT  ...  NaN       NaN   \n",
       "2                  NaN        NaN         NaT         NaT  ...  NaN       NaN   \n",
       "3                  NaN        NaN         NaT         NaT  ...  NaN       NaN   \n",
       "4                  NaN        NaN         NaT         NaT  ...  NaN       NaN   \n",
       "\n",
       "  marital_status religion calc_current_age_death_age svi_socio_econ  \\\n",
       "0            NaN      NaN                        NaN            NaN   \n",
       "1            NaN      NaN                        NaN            NaN   \n",
       "2            NaN      NaN                        NaN            NaN   \n",
       "3            NaN      NaN                        NaN            NaN   \n",
       "4            NaN      NaN                        NaN            NaN   \n",
       "\n",
       "  svi_hcomp_lang svi_mino_lang svi_htyp_trans svi_total  \n",
       "0            NaN           NaN            NaN       NaN  \n",
       "1            NaN           NaN            NaN       NaN  \n",
       "2            NaN           NaN            NaN       NaN  \n",
       "3            NaN           NaN            NaN       NaN  \n",
       "4            NaN           NaN            NaN       NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_all_calls_demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "study_id                              object\n",
       "username_1                            object\n",
       "timestamp_1                   datetime64[ns]\n",
       "call_date_1                   datetime64[ns]\n",
       "call_output_1                         object\n",
       "call_notes_1                          object\n",
       "verbal_consent_1                      object\n",
       "username_2                            object\n",
       "timestamp_2                   datetime64[ns]\n",
       "call_date_2                   datetime64[ns]\n",
       "call_output_2                         object\n",
       "call_notes_2                          object\n",
       "verbal_consent_2                      object\n",
       "username_3                            object\n",
       "timestamp_3                   datetime64[ns]\n",
       "call_date_3                   datetime64[ns]\n",
       "call_output_3                         object\n",
       "call_notes_3                          object\n",
       "verbal_consent_3                      object\n",
       "gender                                object\n",
       "race                                  object\n",
       "ethnicity                             object\n",
       "marital_status                        object\n",
       "religion                              object\n",
       "calc_current_age_death_age           float64\n",
       "svi_socio_econ                       float64\n",
       "svi_hcomp_lang                       float64\n",
       "svi_mino_lang                        float64\n",
       "svi_htyp_trans                       float64\n",
       "svi_total                            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_all_calls_demo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2752"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_all_calls_demo.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
