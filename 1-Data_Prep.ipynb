{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "The data source is a REDCap audit logging file, a REDCap report, and a CSV extract from Clarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_colwidth = 75\n",
    "\n",
    "# import logging file from REDCap (REDCap > Sidebar > Logging > Export all logging (CSV))\n",
    "log = pd.read_csv('data/raw/UCIInternalREDCapPCORIProject_Logging_2020-12-03_1902.csv')\n",
    "\n",
    "# import extract aka \"report\" of useful data from REDCap (REDCap > Sidebar > Data Exports, Reports, and Stats)\n",
    "redcap_extract = pd.read_csv('data/raw/UCIInternalREDCapPCO-AdminExportForRecrui_DATA_2020-12-30_2322.csv')\n",
    "\n",
    "# import extract used for intervention tracking from Clarity\n",
    "clarity_extract = pd.read_csv('data/raw/20201229_PCORIWeeklyExtract.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "### Log: Split into round 1 / 2 / 3 call dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Round 1 Call Updates:  790\n",
      "# of Round 2 Call Updates:  509\n",
      "# of Round 3 Call Updates:  287\n",
      "\n",
      "Total Call Updates:  1586\n"
     ]
    }
   ],
   "source": [
    "# make a new df with only REDCap Patient Record Updates\n",
    "log_updates = log[log['Action'].str.contains(\"Updated\")].copy()\n",
    "\n",
    "# make a new df with only REDCap Patient Record Updates + Phone Call 1 / 2 / 3 Attempts\n",
    "# assumes that RA updating the contact date field in Internal REDCAp = call completed\n",
    "log_updates_call1 = log_updates[log_updates['List of Data Changes OR Fields Exported'].str.contains(\"contact1_dt\", na=False)].copy()\n",
    "log_updates_call2 = log_updates[log_updates['List of Data Changes OR Fields Exported'].str.contains(\"contact2_dt\", na=False)].copy()\n",
    "log_updates_call3 = log_updates[log_updates['List of Data Changes OR Fields Exported'].str.contains(\"contact3_dt\", na=False)].copy()\n",
    "\n",
    "print(\"# of Round 1 Call Updates: \", log_updates_call1.shape[0])\n",
    "print(\"# of Round 2 Call Updates: \", log_updates_call2.shape[0])\n",
    "print(\"# of Round 3 Call Updates: \", log_updates_call3.shape[0])\n",
    "print(\"\\nTotal Call Updates: \", log_updates_call1.shape[0] + log_updates_call2.shape[0] + log_updates_call3.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log: obtain study ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract study ID from long string ('Action')\n",
    "log_updates_call1['study_id'] = log_updates_call1['Action'].str.split(' ').str[2]\n",
    "log_updates_call2['study_id'] = log_updates_call2['Action'].str.split(' ').str[2]\n",
    "log_updates_call3['study_id'] = log_updates_call3['Action'].str.split(' ').str[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log: handle duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original round 1 duplicates:  0\n",
      "original round 2 duplicates:  7\n",
      "original round 3 duplicates:  2\n",
      "\n",
      "new round 1 duplicates:  0\n",
      "new round 2 duplicates:  0\n",
      "new round 3 duplicates:  0\n",
      "\n",
      "# of Round 1 Calls:  790\n",
      "# of Round 2 Calls:  505\n",
      "# of Round 3 Calls:  286\n",
      "\n",
      "Total Calls:  1581\n"
     ]
    }
   ],
   "source": [
    "# convert dtype from string to datetime\n",
    "log_updates_call1['Time / Date'] = pd.to_datetime(log_updates_call1['Time / Date'])\n",
    "log_updates_call2['Time / Date'] = pd.to_datetime(log_updates_call2['Time / Date'])\n",
    "log_updates_call3['Time / Date'] = pd.to_datetime(log_updates_call3['Time / Date'])\n",
    "\n",
    "# sort calls by date from oldest to newest\n",
    "log_updates_call1 = log_updates_call1.sort_values(by=['Time / Date'])\n",
    "log_updates_call2 = log_updates_call2.sort_values(by=['Time / Date'])\n",
    "log_updates_call3 = log_updates_call3.sort_values(by=['Time / Date'])\n",
    "\n",
    "# check for duplicate updates to 1 study ID\n",
    "print(\"original round 1 duplicates: \", log_updates_call1[log_updates_call1['study_id'].duplicated(keep=False)].shape[0])\n",
    "print(\"original round 2 duplicates: \", log_updates_call2[log_updates_call2['study_id'].duplicated(keep=False)].shape[0])\n",
    "print(\"original round 3 duplicates: \", log_updates_call3[log_updates_call3['study_id'].duplicated(keep=False)].shape[0])\n",
    "\n",
    "# when there are multiple updates to 1 study ID, only take the most recent update\n",
    "unique_log_updates_call1 = log_updates_call1.drop_duplicates(subset=['study_id'], keep='last')\n",
    "unique_log_updates_call2 = log_updates_call2.drop_duplicates(subset=['study_id'], keep='last')\n",
    "unique_log_updates_call3 = log_updates_call3.drop_duplicates(subset=['study_id'], keep='last')\n",
    "\n",
    "# check for duplicate updates to 1 study ID\n",
    "print(\"\\nnew round 1 duplicates: \", unique_log_updates_call1[unique_log_updates_call1['study_id'].duplicated(keep=False)].shape[0])\n",
    "print(\"new round 2 duplicates: \", unique_log_updates_call2[unique_log_updates_call2['study_id'].duplicated(keep=False)].shape[0])\n",
    "print(\"new round 3 duplicates: \", unique_log_updates_call3[unique_log_updates_call3['study_id'].duplicated(keep=False)].shape[0])\n",
    "\n",
    "print(\"\\n# of Round 1 Calls: \", unique_log_updates_call1.shape[0])\n",
    "print(\"# of Round 2 Calls: \", unique_log_updates_call2.shape[0])\n",
    "print(\"# of Round 3 Calls: \", unique_log_updates_call3.shape[0])\n",
    "print(\"\\nTotal Calls: \", unique_log_updates_call1.shape[0] + unique_log_updates_call2.shape[0] + unique_log_updates_call3.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log: extract useful data from strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names:  ['study_id', 'caller_username_1', 'call_timestamp_1', 'call_date_1', 'call_output_1', 'call_notes_1', 'call_verbal_consent_1']\n",
      "shape of round 1 dataset:  (790, 7)\n",
      "shape of round 2 dataset:  (505, 7)\n",
      "shape of round 3 dataset:  (286, 7)\n"
     ]
    }
   ],
   "source": [
    "# extract individual updates from long string ('List of Data Changes OR Fields Exported'), based on delimiter ','\n",
    "split_unique_log_updates_call1 = pd.concat([unique_log_updates_call1['study_id'], \n",
    "                                     unique_log_updates_call1['List of Data Changes OR Fields Exported'].str.split(',', expand=True)],\n",
    "                                    axis=1,)\n",
    "split_unique_log_updates_call2 = pd.concat([unique_log_updates_call2['study_id'],\n",
    "                                     unique_log_updates_call2['List of Data Changes OR Fields Exported'].str.split(',', expand=True)],\n",
    "                                    axis=1,)\n",
    "split_unique_log_updates_call3 = pd.concat([unique_log_updates_call3['study_id'],\n",
    "                                     unique_log_updates_call3['List of Data Changes OR Fields Exported'].str.split(',', expand=True)],\n",
    "                                    axis=1,)\n",
    "\n",
    "\n",
    "\n",
    "# extract updates specific to round 1 / 2 / 3 phone calls \n",
    "# make a boolean mask of all columns in the round 1 / 2 / 3 dataframe, True for matching strings\n",
    "# forward fill rows with matching strings and take only the last value \n",
    "# basically picks out the matching value regardless of column location and places it into the correct column\n",
    "\n",
    "# round 1\n",
    "df = split_unique_log_updates_call1.copy()\n",
    "strings = ['contact1_dt', 'contact1_output', 'contact1_nt', 'verbal_yn']\n",
    "updates_round_1 = pd.DataFrame()\n",
    "\n",
    "for s in strings:\n",
    "    for col in df: \n",
    "        df[col] = df[col].mask(~df[col].str.contains(s, na=False))\n",
    "    updates_round_1[s] = df.ffill(axis=1).iloc[:, -1]\n",
    "    df = split_unique_log_updates_call1.copy()\n",
    "\n",
    "# extracts date from 'contact1_dt' output\n",
    "updates_round_1.iloc[:,0] = pd.to_datetime(updates_round_1.iloc[:,0].str.extract('(\\d{1,4}-\\d{1,2}-\\d{1,2})')[0])\n",
    "\n",
    "# convert call code outputs to real words, per UCI's REDCap Codebook \n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '1'\": \"No answer/unable to leave VM/busy/disconnected\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '2'\": \"Left a message\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '3'\": \"Call back later\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '4'\": \"Hasn't received packet yet, call back in one week\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '5'\": \"Hasn't received packet and team needs to resend in the mail\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '6'\": \"Send link to the survey\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '7'\": \"Completed survey by phone\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '8'\": \"Patient refused\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '9'\": \"Deceased\"}, regex=True)\n",
    "updates_round_1.iloc[:,1] = updates_round_1.iloc[:,1].replace({\"contact1_output = '10'\": \"Other Notes\"}, regex=True)\n",
    "\n",
    "updates_round_1.iloc[:,3] = updates_round_1.iloc[:,3].replace({\"verbal_yn = '0'\": \"No Verbal Consent\"}, regex=True)\n",
    "updates_round_1.iloc[:,3] = updates_round_1.iloc[:,3].replace({\"verbal_yn = '1'\": \"Yes Verbal Consent\"}, regex=True)\n",
    "    \n",
    "    \n",
    "# round 2\n",
    "df = split_unique_log_updates_call2.copy()\n",
    "strings = ['contact2_dt', 'contact2_output', 'contact2_nt', 'verbal_yn']\n",
    "updates_round_2 = pd.DataFrame()\n",
    "\n",
    "for s in strings:\n",
    "    for col in df: \n",
    "        df[col] = df[col].mask(~df[col].str.contains(s, na=False))\n",
    "    updates_round_2[s] = df.ffill(axis=1).iloc[:, -1]\n",
    "    df = split_unique_log_updates_call2.copy()\n",
    "\n",
    "updates_round_2.iloc[:,0] = pd.to_datetime(updates_round_2.iloc[:,0].str.extract('(\\d{1,4}-\\d{1,2}-\\d{1,2})')[0])\n",
    "\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '1'\": \"No answer/unable to leave VM/busy/disconnected\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '2'\": \"Left a message\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '3'\": \"Call back later\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '4'\": \"Hasn't received packet yet, call back in one week\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '5'\": \"Hasn't received packet and team needs to resend in the mail\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '6'\": \"Send link to the survey\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '7'\": \"Completed survey by phone\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '8'\": \"Patient refused\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '9'\": \"Deceased\"}, regex=True)\n",
    "updates_round_2.iloc[:,1] = updates_round_2.iloc[:,1].replace({\"contact2_output = '10'\": \"Other Notes\"}, regex=True)\n",
    "\n",
    "updates_round_2.iloc[:,3] = updates_round_2.iloc[:,3].replace({\"verbal_yn = '0'\": \"No Verbal Consent\"}, regex=True)\n",
    "updates_round_2.iloc[:,3] = updates_round_2.iloc[:,3].replace({\"verbal_yn = '1'\": \"Yes Verbal Consent\"}, regex=True)\n",
    "\n",
    "\n",
    "# round 3\n",
    "df = split_unique_log_updates_call3.copy()\n",
    "strings = ['contact3_dt', 'contact3_output', 'contact3_nt', 'verbal_yn']\n",
    "updates_round_3 = pd.DataFrame()\n",
    "\n",
    "for s in strings:\n",
    "    for col in df: \n",
    "        df[col] = df[col].mask(~df[col].str.contains(s, na=False))\n",
    "    updates_round_3[s] = df.ffill(axis=1).iloc[:, -1]\n",
    "    df = split_unique_log_updates_call3.copy()\n",
    "\n",
    "updates_round_3.iloc[:,0] = pd.to_datetime(updates_round_3.iloc[:,0].str.extract('(\\d{1,4}-\\d{1,2}-\\d{1,2})')[0])\n",
    "\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '1'\": \"No answer/unable to leave VM/busy/disconnected\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '2'\": \"Left a message\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '3'\": \"Call back later\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '4'\": \"Hasn't received packet yet, call back in one week\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '5'\": \"Hasn't received packet and team needs to resend in the mail\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '6'\": \"Send link to the survey\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '7'\": \"Completed survey by phone\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '8'\": \"Patient refused\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '9'\": \"Deceased\"}, regex=True)\n",
    "updates_round_3.iloc[:,1] = updates_round_3.iloc[:,1].replace({\"contact3_output = '10'\": \"Other Notes\"}, regex=True)\n",
    "\n",
    "updates_round_3.iloc[:,3] = updates_round_3.iloc[:,3].replace({\"verbal_yn = '0'\": \"No Verbal Consent\"}, regex=True)\n",
    "updates_round_3.iloc[:,3] = updates_round_3.iloc[:,3].replace({\"verbal_yn = '1'\": \"Yes Verbal Consent\"}, regex=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create new dataframes with relevant columns for round 1 / 2 / 3 calls \n",
    "\n",
    "# round 1\n",
    "clean_round_1 = split_unique_log_updates_call1['study_id'].copy()\n",
    "clean_round_1 = pd.concat((clean_round_1, unique_log_updates_call1['Username']), axis=1)\n",
    "clean_round_1 = pd.concat((clean_round_1, unique_log_updates_call1['Time / Date']), axis=1)\n",
    "clean_round_1 = pd.concat((clean_round_1, updates_round_1), axis=1)\n",
    "clean_round_1.columns = ['study_id', 'caller_username_1', 'call_timestamp_1', 'call_date_1', 'call_output_1', 'call_notes_1', 'call_verbal_consent_1']\n",
    "\n",
    "\n",
    "# round 2 \n",
    "clean_round_2 = split_unique_log_updates_call2['study_id'].copy()\n",
    "clean_round_2 = pd.concat((clean_round_2, unique_log_updates_call2['Username']), axis=1)\n",
    "clean_round_2 = pd.concat((clean_round_2, unique_log_updates_call2['Time / Date']), axis=1)\n",
    "clean_round_2 = pd.concat((clean_round_2, updates_round_2), axis=1)\n",
    "clean_round_2.columns = ['study_id', 'caller_username_2', 'call_timestamp_2', 'call_date_2', 'call_output_2', 'call_notes_2', 'call_verbal_consent_2']\n",
    "\n",
    "\n",
    "# round 3\n",
    "clean_round_3 = split_unique_log_updates_call3['study_id'].copy()\n",
    "clean_round_3 = pd.concat((clean_round_3, unique_log_updates_call3['Username']), axis=1)\n",
    "clean_round_3 = pd.concat((clean_round_3, unique_log_updates_call3['Time / Date']), axis=1)\n",
    "clean_round_3 = pd.concat((clean_round_3, updates_round_3), axis=1)\n",
    "clean_round_3.columns = ['study_id', 'caller_username_3', 'call_timestamp_3', 'call_date_3', 'call_output_3', 'call_notes_3', 'call_verbal_consent_3']\n",
    "\n",
    "\n",
    "print(\"column names: \", clean_round_1.columns.values.tolist())\n",
    "print(\"shape of round 1 dataset: \", clean_round_1.shape)\n",
    "print(\"shape of round 2 dataset: \", clean_round_2.shape)\n",
    "print(\"shape of round 3 dataset: \", clean_round_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REDCap Extract: convert number coding to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCI had one unique case where a patient specifically asked not to receive a gift card, even after completing the survey\n",
    "# The RAs commented this in REDCap and left the \"Gift Card Type\" field blank\n",
    "# blank fields are problematic for the conversions below, so I converted this one to the int 99\n",
    "# NOTE: this will soon be irrelevant, I'm going to just add another dropdown option for \"Patient Declined\"\n",
    "# TODO: expand REDCap report criteria to NOT only include patients that sent in surveys\n",
    "redcap_extract.iloc[:,10] = redcap_extract.iloc[:,10].replace(np.nan, 99)\n",
    "\n",
    "# convert the only float column to an int before converting everything to string\n",
    "redcap_extract['gift_card_type'] = redcap_extract['gift_card_type'].apply(int)\n",
    "redcap_extract = redcap_extract.applymap(str)\n",
    "\n",
    "# convert dates back to datetime data type\n",
    "redcap_extract['survey_completed_dt'] = pd.to_datetime(redcap_extract['survey_completed_dt'])\n",
    "redcap_extract['consent_received_dt'] = pd.to_datetime(redcap_extract['consent_received_dt'])\n",
    "redcap_extract['hipaa_received_dt'] = pd.to_datetime(redcap_extract['hipaa_received_dt'])\n",
    "redcap_extract['consent_mailed_dt'] = pd.to_datetime(redcap_extract['consent_mailed_dt'])\n",
    "\n",
    "redcap_extract.iloc[:,2] = redcap_extract.iloc[:,2].replace({\"0\": \"English\"}, regex=True)\n",
    "redcap_extract.iloc[:,2] = redcap_extract.iloc[:,2].replace({\"1\": \"Spanish\"}, regex=True)\n",
    "\n",
    "redcap_extract.iloc[:,3] = redcap_extract.iloc[:,3].replace({\"0\": \"No HIPAA Sent\"}, regex=True)\n",
    "redcap_extract.iloc[:,3] = redcap_extract.iloc[:,3].replace({\"1\": \"Yes HIPAA Sent\"}, regex=True)\n",
    "\n",
    "redcap_extract.iloc[:,6] = redcap_extract.iloc[:,6].replace({\"1\": \"Paper\"}, regex=True)\n",
    "redcap_extract.iloc[:,6] = redcap_extract.iloc[:,6].replace({\"2\": \"Phone\"}, regex=True)\n",
    "redcap_extract.iloc[:,6] = redcap_extract.iloc[:,6].replace({\"3\": \"Email\"}, regex=True)\n",
    "\n",
    "redcap_extract.iloc[:,10] = redcap_extract.iloc[:,10].replace({\"1\": \"e-Gift Card\"}, regex=True)\n",
    "redcap_extract.iloc[:,10] = redcap_extract.iloc[:,10].replace({\"2\": \"Physical Gift Card\"}, regex=True)\n",
    "redcap_extract.iloc[:,10] = redcap_extract.iloc[:,10].replace({\"3\": \"Target Gift Card\"}, regex=True)\n",
    "redcap_extract.iloc[:,10] = redcap_extract.iloc[:,10].replace({\"99\": \"Patient Declined\"}, regex=True)\n",
    "\n",
    "# NOTE: may want to add some additional items from Internal REDCap\n",
    "useful_redcap_cols = ['study_id', 'survey_language_sent', 'hipaa_sent_yn', 'survey_completed_dt', \n",
    "                      'consent_received_dt', 'survery_completed_method',  'hipaa_received_dt', \n",
    "                      'caregiver_name', 'consent_mailed_dt', 'gift_card_type']\n",
    "\n",
    "clean_redcap_extract = redcap_extract.filter(useful_redcap_cols).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clarity Extract: calculate age and convert data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates to datetime data type\n",
    "clarity_extract['birth_date'] = pd.to_datetime(clarity_extract['birth_date'])\n",
    "clarity_extract['death_date'] = pd.to_datetime(clarity_extract['death_date'])\n",
    "\n",
    "# convert int to string for consistency\n",
    "clarity_extract['study_id'] = clarity_extract.astype(str)\n",
    "\n",
    "# calculate age from today's date, unless patient is dead (then use deceased date)\n",
    "# NOTE: may want to make this more precise and account for months \n",
    "def calculate_age(dob, dod): \n",
    "    today = date.today()\n",
    "    if dod is pd.NaT: \n",
    "        return today.year - dob.year\n",
    "    else: \n",
    "        return dod.year - dob.year\n",
    "\n",
    "clarity_extract['age'] = clarity_extract.apply(lambda x: calculate_age(x['birth_date'], x['death_date']), axis=1)\n",
    "\n",
    "\n",
    "# TODO: ask Rick for marital status, religion\n",
    "# TODO: ask Javi to include spoken lang, written lang\n",
    "useful_clarity_cols = ['study_id', 'sex', 'race', 'ethnicity', 'age', 'spoken_language', 'written_language']\n",
    "\n",
    "clean_clarity_extract = clarity_extract.filter(useful_clarity_cols).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join REDCap Extract, REDCap Log, and Clarity Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of patients who were called at least 1 time and / or returned a survey:  869\n",
      "\n",
      "\n",
      "Columns:  ['study_id', 'caller_username_1', 'call_timestamp_1', 'call_date_1', 'call_output_1', 'call_notes_1', 'call_verbal_consent_1', 'caller_username_2', 'call_timestamp_2', 'call_date_2', 'call_output_2', 'call_notes_2', 'call_verbal_consent_2', 'caller_username_3', 'call_timestamp_3', 'call_date_3', 'call_output_3', 'call_notes_3', 'call_verbal_consent_3', 'survey_language_sent', 'hipaa_sent_yn', 'survey_completed_dt', 'consent_received_dt', 'survery_completed_method', 'hipaa_received_dt', 'caregiver_name', 'consent_mailed_dt', 'gift_card_type', 'sex', 'race', 'ethnicity', 'age', 'spoken_language', 'written_language']\n"
     ]
    }
   ],
   "source": [
    "# merge round 1 / 2 / 3 calls so there is 1 patient per line with all call data in columns \n",
    "clean_1_2_calls = pd.merge(clean_round_1, clean_round_2, how='left', on='study_id')\n",
    "clean_all_calls = pd.merge(clean_1_2_calls, clean_round_3, how='left', on='study_id')\n",
    "\n",
    "# join patients who were called with patients who returned surveys (source: REDCap report / extract)\n",
    "calls_and_redcap = pd.merge(clean_all_calls, clean_redcap_extract, how='outer', on='study_id')\n",
    "\n",
    "# get full clarity data on patients who were called and / or returned surveys \n",
    "calls_and_recap_and_clarity = pd.merge(calls_and_redcap, clean_clarity_extract, how='left', on='study_id')\n",
    "\n",
    "#print(\"Example output for each patient who sent in a survey:\\n\\n\", calls_and_recap_and_clarity.loc[calls_and_recap_and_clarity['study_id'] == \"...\"])\n",
    "\n",
    "print(\"Total # of patients who were called at least 1 time and / or returned a survey: \", calls_and_recap_and_clarity.shape[0])\n",
    "print(\"\\n\\nColumns: \", calls_and_recap_and_clarity.columns.values.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
